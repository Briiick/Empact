<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Empact - Demo</title>
    <meta content="width=1024" name="viewport">
    <meta author="David Janghoon Lee">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/materialize/1.0.0/css/materialize.min.css">
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
    <script src="https://download.affectiva.com/js/3.2.1/affdex.js"></script>
    <script src="https://code.jquery.com/jquery-3.3.1.js" integrity="sha256-2Kok7MbOyxpgUVvAk/HJ2jigOSYS2auK4Pfzbm7uH60=" crossorigin="anonymous"></script>
    <style>
        #affdex_elements {
            margin-top: 9px;
        }

        #face_video_canvas{
            -webkit-transform: scaleX(-1);
            transform: scaleX(-1);
        }

        video {
            width: 500px;
            height: 385px;
            -webkit-transform: scaleX(-1);
            transform: scaleX(-1);
        }

        h5 {
            color: gray;
        }
    </style>
</head>
<body>
    <div class="navbar-fixed">
        <nav style="background-color: rgb(13, 28, 41);">
            <div class="nav-wrapper container">
                <img src="empact_logo.png" href="/" class="img img-responsive">
            </div>
        </nav> 
    </div>
    <div class="container">
        <h5 class="center">Visit on a desktop browser for complete experience!</h5>
        <div class="row">
            <div class="col m12 l6 s12" id="affdex_elements"></div>
            <div class="col m12 l6 s12">
                <h3>Facial Emotion:</h3>
                <div>
                    <div id="results"></div>
                </div>
                <div id="logs"></div>
            </div>
        </div>
        <div>
            <button style="background-color: rgb(13, 28, 41);" class="btn" id="start" onclick="onStart()">Start</button>
            <button style="background-color: rgb(13, 28, 41);" class="btn" id="stop" onclick="onStop()">Stop</button>
            <input style="background-color: rgb(13, 28, 41);" type="button" class="btn" value="Reset" onClick="window.location.reload()">
        </div>
        <br>
    </div>
<script>
    ///////////////////////////////////////////////////////////////////////////////////////////////////////////////
    // Initiation code borrowed from https://jsfiddle.net/affectiva/opyh5e8d/show/
    // All rights of the open source code to Affectiva.com
    // SDK Needs to create video and canvas nodes in the DOM in order to function
    // Here we are adding those nodes a predefined div.
    var divRoot = $("#affdex_elements")[0];
    var width = 500;
    var height = 385;
    var faceMode = affdex.FaceDetectorMode.LARGE_FACES;
    //Construct a CameraDetector and specify the image width / height and face detector mode.
    var detector = new affdex.CameraDetector(divRoot, width, height, faceMode);

    //Enable detection of all Expressions, Emotions and Emojis classifiers.
    detector.detectAllEmotions();
    //detector.detectAllExpressions();
    detector.detectAllEmojis();
    //detector.detectAllAppearance();

    //Add a callback to notify when the detector is initialized and ready for runing.
    detector.addEventListener("onInitializeSuccess", function() {
        log('#logs', "Initialized. Let your face be detected my camera!");
        //Display canvas instead of video feed because we want to draw the feature points on it
        $("#face_video_canvas").css("display", "block").css("scale", "scaleX(-1)");
        $("#face_video").css("display", "none").css("scale", "scaleX(-1)");
    });

    function log(node_name, msg) {
        $(node_name).append("<span>" + msg + "</span><br />")
    }

    function logNode(node_name, msg) {
        $(node_name).append("<h4>" + msg + "</h4>")
    }

    //function executes when Start button is pushed.
    function onStart() {
        if (detector && !detector.isRunning) {
            $("#logs").html("");
            detector.start();
        }
        log('#logs', "Starting...please wait :)");
    }

    //function executes when the Stop button is pushed.
    function onStop() {
        log('#logs', "Stopped!");
        if (detector && detector.isRunning) {
            detector.removeEventListener();
            detector.stop();
        }
    };
    
    //Add a callback to receive the results from processing an image.
    //The faces object contains the list of the faces detected in an image.
    //Faces object contains probabilities for all the different expressions, emotions and appearance metrics
    detector.addEventListener("onImageResultsSuccess", function(faces, image, timestamp) {
        $('#results').html("");
        if (faces.length > 0) {
            returnHtml = ""

            obj = faces[0].emotions

            happy = obj.joy;
            surprise = obj.surprise;
            sad = obj.valence;
            angry = obj.anger;
            if (happy > 30) {
                returnHtml = "Happy: " + happy.toFixed(2) + "%"
            } else if (surprise > 30){
                returnHtml = "Surprise: " + surprise.toFixed(2) + "%"
            } else if (angry > 20){
                returnHtml = "Angry: " + angry.toFixed(2) + "%"
            } else if (sad < -60){
                returnHtml = "Sadness: " + Math.abs(sad).toFixed(2) + "%"
            } else {
                returnHtml = "Normal:<br>"
            }

           
            emotions = JSON.stringify(faces[0].emotions, function(key, val) {
                return val.toFixed ? Number(val.toFixed(0)) : val;
            });

            //console.log(obj.joy);
            //$('#result').append(emotions['joy']);
            logNode('#results', returnHtml);
            logNode('#results', "Face: " + faces[0].emojis.dominantEmoji);
            if($('#face_video_canvas')[0] != null)
                drawFeaturePoints(image, faces[0].featurePoints);
        }
    });

    //Draw the detected facial feature points on the image
    function drawFeaturePoints(img, featurePoints) {
        var contxt = $('#face_video_canvas')[0].getContext('2d');

        var hRatio = contxt.canvas.width / img.width;
        var vRatio = contxt.canvas.height / img.height;
        var ratio = Math.min(hRatio, vRatio);

        contxt.strokeStyle = "#FFFFFF";
        for (var id in featurePoints) {
        contxt.beginPath();
        contxt.arc(featurePoints[id].x,
        featurePoints[id].y, 2, 0, 2 * Math.PI);
        contxt.stroke();
        }
    }

    document.addEventListener('DOMContentLoaded', function() {
        var elem = document.querySelector('.modal');
        var instance = M.Modal.init(elem, {});
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/materialize/1.0.0/js/materialize.min.js"></script>
</body>
</html>


